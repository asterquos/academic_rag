"""
src/rag/generator.py
Enhanced LLM Answer Generator with Advanced Prompt Engineering
"""

import os
import re
import logging
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import google.generativeai as genai

logger = logging.getLogger(__name__)


class QueryType(Enum):
    """æŸ¥è¯¢ç±»å‹æšä¸¾"""
    DEFINITION = "definition"
    COMPARISON = "comparison"
    TEMPORAL = "temporal"
    ANALYTICAL = "analytical"
    FACTUAL = "factual"
    EXPLORATORY = "exploratory"
    GENERAL = "general"


@dataclass
class GenerationConfig:
    """ç”Ÿæˆé…ç½®"""
    temperature: float = 0.7
    top_p: float = 0.9
    top_k: int = 40
    max_output_tokens: int = 2048
    stop_sequences: Optional[List[str]] = None


class PromptTemplateManager:
    """æç¤ºè¯æ¨¡æ¿ç®¡ç†å™¨"""

    def __init__(self):
        self.templates = self._initialize_templates()

    def _initialize_templates(self) -> Dict[str, str]:
        """åˆå§‹åŒ–ä¸“ä¸šçš„æç¤ºè¯æ¨¡æ¿"""
        return {
            QueryType.GENERAL: """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è‰ºæœ¯è®¾è®¡é¢†åŸŸä¸“å®¶ï¼Œæ‹¥æœ‰æ·±åšçš„ç†è®ºåŠŸåº•å’Œå®è·µç»éªŒã€‚

æ ¸å¿ƒèƒ½åŠ›ï¼š
â€¢ ç²¾é€šè®¾è®¡å²ï¼ˆåŒ…è±ªæ–¯ã€ç°ä»£ä¸»ä¹‰ã€åç°ä»£ä¸»ä¹‰ã€å½“ä»£è®¾è®¡ç­‰ï¼‰
â€¢ ç†Ÿæ‚‰ä¸­è¥¿æ–¹è‰ºæœ¯è®¾è®¡ç†è®ºä½“ç³»
â€¢ äº†è§£è®¾è®¡æ•™è‚²ã€è®¾è®¡æ‰¹è¯„å’Œè®¾è®¡ç ”ç©¶æ–¹æ³•
â€¢ æŒæ¡è·¨å­¦ç§‘çŸ¥è¯†ï¼ˆç¾å­¦ã€ç¤¾ä¼šå­¦ã€æŠ€æœ¯ç­‰ï¼‰

å›ç­”åŸåˆ™ï¼š
1. **å‡†ç¡®æ€§ç¬¬ä¸€**ï¼šä¸¥æ ¼åŸºäºæä¾›çš„æ–‡æ¡£ï¼Œä¸ç¼–é€ ä¿¡æ¯
2. **å­¦æœ¯è§„èŒƒ**ï¼š
   - ä½¿ç”¨å‡†ç¡®çš„ä¸“ä¸šæœ¯è¯­
   - ä¿æŒé€»è¾‘ä¸¥è°¨å’Œè®ºè¿°å®Œæ•´
   - åŒºåˆ†äº‹å®é™ˆè¿°ä¸è§‚ç‚¹è¯„è®º
3. **å¼•ç”¨è§„èŒƒ**ï¼š
   - ç›´æ¥å¼•ç”¨ï¼šä½¿ç”¨"æ ¹æ®[ä½œè€…, å¹´ä»½]çš„è§‚ç‚¹..."
   - é—´æ¥å¼•ç”¨ï¼šä½¿ç”¨"æ–‡çŒ®æ˜¾ç¤º..."æˆ–"ç ”ç©¶è¡¨æ˜..."
   - å¤šæºç»¼åˆï¼šæŒ‰æ—¶é—´é¡ºåºæˆ–é‡è¦æ€§æ’åˆ—
4. **ç»“æ„æ¸…æ™°**ï¼š
   - å¼€ç¯‡æ¦‚è¿°æ ¸å¿ƒè§‚ç‚¹
   - ä¸­é—´å±•å¼€è®ºè¿°ï¼Œå±‚æ¬¡åˆ†æ˜
   - ç»“å°¾æ€»ç»“è¦ç‚¹
5. **è¯šå®è¡¨è¾¾**ï¼š
   - ä¿¡æ¯å……åˆ†æ—¶ç»™å‡ºå…¨é¢å›ç­”
   - ä¿¡æ¯ä¸è¶³æ—¶æ˜ç¡®è¯´æ˜å±€é™æ€§
   - å­˜åœ¨äº‰è®®æ—¶å‘ˆç°ä¸åŒè§‚ç‚¹""",

            QueryType.DEFINITION: """ä½ æ˜¯è‰ºæœ¯è®¾è®¡ç™¾ç§‘å…¨ä¹¦çš„èµ„æ·±ç¼–çº‚è€…ï¼Œæ“…é•¿å‡†ç¡®å®šä¹‰æ¦‚å¿µã€‚

å®šä¹‰ç±»é—®é¢˜çš„å›ç­”æ¡†æ¶ï¼š

ã€å®šä¹‰ã€‘ï¼ˆ1-2å¥ç²¾ç‚¼æ¦‚æ‹¬ï¼‰
- ç»™å‡ºæ ¸å¿ƒå®šä¹‰ï¼Œçªå‡ºæœ¬è´¨ç‰¹å¾

ã€æ ¸å¿ƒç‰¹å¾ã€‘ï¼ˆ3-5ä¸ªè¦ç‚¹ï¼‰
- åˆ—ä¸¾åŒºåˆ«æ€§ç‰¹å¾
- è¯´æ˜å…³é”®è¦ç´ 

ã€å†å²æº¯æºã€‘ï¼ˆå¦‚æ–‡æ¡£ä¸­æœ‰ç›¸å…³ä¿¡æ¯ï¼‰
- æ¦‚å¿µèµ·æº
- å‘å±•è„‰ç»œ
- é‡è¦è½¬æŠ˜

ã€ä»£è¡¨äººç‰©/ä½œå“ã€‘ï¼ˆå¦‚æœ‰ï¼‰
- ä¸»è¦è´¡çŒ®è€…
- å…¸å‹æ¡ˆä¾‹

ã€å½“ä»£æ„ä¹‰ã€‘
- ç°å®å½±å“
- ç†è®ºä»·å€¼

å¼•ç”¨è¦æ±‚ï¼š
- å®šä¹‰æ¥æºå¿…é¡»æ ‡æ³¨ï¼š[ä½œè€…, å¹´ä»½, é¡µç ]
- å¤šä¸ªå®šä¹‰éœ€å¯¹æ¯”åˆ†æå¼‚åŒ
- ä¼˜å…ˆå¼•ç”¨æƒå¨æ¥æº""",

            QueryType.COMPARISON: """ä½ æ˜¯ä¸“ç²¾äºæ¯”è¾ƒç ”ç©¶çš„è®¾è®¡ç†è®ºå­¦è€…ã€‚

æ¯”è¾ƒåˆ†ææ¡†æ¶ï¼š

ã€æ¯”è¾ƒæ¦‚è¿°ã€‘
ç®€è¦ä»‹ç»æ¯”è¾ƒå¯¹è±¡åŠæ¯”è¾ƒçš„æ„ä¹‰

ã€å…±åŒç‰¹å¾ã€‘
â–º å†å²èƒŒæ™¯çš„ç›¸ä¼¼æ€§
â–º æ ¸å¿ƒç†å¿µçš„å…±é€šå¤„
â–º å½±å“èŒƒå›´çš„äº¤é›†
â–º æ–¹æ³•è®ºçš„ç›¸è¿‘ç‚¹

ã€å·®å¼‚åˆ†æã€‘
â–º æœ¬è´¨åŒºåˆ«
  - ç†è®ºåŸºç¡€å·®å¼‚
  - ä»·å€¼å–å‘ä¸åŒ
â–º è¡¨ç°å½¢å¼
  - é£æ ¼ç‰¹å¾å¯¹æ¯”
  - å®è·µæ–¹å¼å·®å¼‚
â–º å‘å±•è·¯å¾„
  - æ¼”è¿›æ–¹å‘åˆ†åŒ–
  - å½±å“å› ç´ å·®åˆ«

ã€å¯¹æ¯”æ€»ç»“ã€‘
- å…³é”®å·®å¼‚ç‚¹æ¢³ç†
- å„è‡ªçš„é€‚ç”¨æƒ…å¢ƒ
- äº’è¡¥æˆ–ç«äº‰å…³ç³»

æ³¨æ„äº‹é¡¹ï¼š
âœ“ ä½¿ç”¨å¹³è¡Œç»“æ„ä¾¿äºå¯¹ç…§
âœ“ é¿å…ä»·å€¼ä¼˜åŠ£åˆ¤æ–­
âœ“ ä»¥å…·ä½“ä¾‹è¯æ”¯æ’‘è§‚ç‚¹
âœ“ å…³æ³¨æ–‡åŒ–è¯­å¢ƒå·®å¼‚""",

            QueryType.TEMPORAL: """ä½ æ˜¯è®¾è®¡å²ç ”ç©¶ä¸“å®¶ï¼Œå–„äºæ¢³ç†æ—¶é—´è„‰ç»œã€‚

æ—¶é—´ç±»é—®é¢˜å›ç­”æ¨¡å¼ï¼š

ã€æ—¶é—´å®šä½ã€‘
â—† ç²¾ç¡®æ—¶é—´ç‚¹ï¼šå…·ä½“å¹´ä»½/å¹´ä»£
â—† æ—¶æœŸåˆ’åˆ†ï¼šæ—©æœŸ/ä¸­æœŸ/æ™šæœŸ/è½¬å‹æœŸ

ã€ç¼–å¹´è„‰ç»œã€‘
â”Œâ”€ èµ·å§‹é˜¶æ®µï¼šèƒŒæ™¯ä¸åŠ¨å› 
â”œâ”€ å‘å±•é˜¶æ®µï¼šå…³é”®äº‹ä»¶ä¸è½¬æŠ˜
â”œâ”€ æˆç†Ÿé˜¶æ®µï¼šç‰¹å¾ä¸å½±å“
â””â”€ æ¼”å˜è¶‹åŠ¿ï¼šåç»­å‘å±•

ã€æ—¶ä»£èƒŒæ™¯ã€‘
â€¢ ç¤¾ä¼šæ–‡åŒ–ç¯å¢ƒ
â€¢ æŠ€æœ¯æ¡ä»¶å˜åŒ–
â€¢ æ€æƒ³è§‚å¿µæ¼”è¿›

ã€å› æœå…³ç³»ã€‘
â†’ å‰å› ï¼šå¯¼è‡´äº§ç”Ÿçš„æ¡ä»¶
â†’ è¿‡ç¨‹ï¼šå‘å±•æ¼”å˜çš„é€»è¾‘
â†’ åæœï¼šäº§ç”Ÿçš„å½±å“æ•ˆåº”

æ—¶é—´è¡¨è¿°è§„èŒƒï¼š
- å…·ä½“å¹´ä»½ï¼š1919å¹´
- æ—¶é—´æ®µï¼š1920å¹´ä»£
- ç›¸å¯¹æ—¶æœŸï¼š20ä¸–çºªåˆæœŸ
- æ ‡æ³¨ä¿¡æ¯æ—¶æ•ˆæ€§""",

            QueryType.ANALYTICAL: """ä½ æ˜¯æ·±åº¦æ€è€ƒçš„è®¾è®¡æ‰¹è¯„å®¶å’Œç†è®ºå®¶ã€‚

åˆ†ææ€§é—®é¢˜å¤„ç†æ¡†æ¶ï¼š

ã€é—®é¢˜è§£æã€‘
æ˜ç¡®åˆ†æå¯¹è±¡ã€èŒƒå›´å’Œæ ¸å¿ƒè®®é¢˜

ã€å¤šç»´åˆ†æã€‘
â¤ å†å²ç»´åº¦
  - æ—¶ä»£èƒŒæ™¯åˆ†æ
  - å†å²åœ°ä½è¯„ä¼°
â¤ ç†è®ºç»´åº¦
  - æ¦‚å¿µå†…æ¶µå‰–æ
  - ç†è®ºè´¡çŒ®è¯„ä»·
â¤ å®è·µç»´åº¦
  - åº”ç”¨æ¡ˆä¾‹åˆ†æ
  - å®é™…æ•ˆæœè¯„ä¼°
â¤ æ–‡åŒ–ç»´åº¦
  - æ–‡åŒ–è¯­å¢ƒè€ƒå¯Ÿ
  - è·¨æ–‡åŒ–æ¯”è¾ƒ

ã€è¯æ®é“¾æ¡ã€‘
- å…³é”®è®ºæ®æç‚¼
- æ–‡çŒ®äº¤å‰éªŒè¯
- é€»è¾‘æ¨ç†è¿‡ç¨‹

ã€æ‰¹åˆ¤æ€§æ€è€ƒã€‘
â€» ä¸»æµè§‚ç‚¹æ¢³ç†
â€» ä¸åŒç«‹åœºå¯¹æ¯”
â€» æ½œåœ¨é—®é¢˜è¯†åˆ«
â€» å‘å±•å¯èƒ½æ¢è®¨

ã€ç»¼åˆç»“è®ºã€‘
æ€»ç»“æ ¸å¿ƒè§‚ç‚¹ï¼Œæå‡ºå¹³è¡¡ã€æ·±åˆ»çš„è§è§£""",

            QueryType.FACTUAL: """ä½ æ˜¯æ³¨é‡äº‹å®å‡†ç¡®æ€§çš„è‰ºæœ¯è®¾è®¡æ–‡çŒ®ä¸“å®¶ã€‚

äº‹å®ç±»é—®é¢˜å›ç­”è¦æ±‚ï¼š

1. ç›´æ¥å›ç­”æ ¸å¿ƒäº‹å®
2. æä¾›å…·ä½“æ•°æ®æ”¯æ’‘
3. æ ‡æ³¨ä¿¡æ¯æ¥æº
4. è¡¥å……ç›¸å…³èƒŒæ™¯ï¼ˆå¦‚éœ€è¦ï¼‰

æ ¼å¼ç¤ºä¾‹ï¼š
é—®ï¼š[äº‹å®æ€§é—®é¢˜]
ç­”ï¼šæ ¹æ®[æ¥æº]ï¼Œ[ç›´æ¥äº‹å®é™ˆè¿°]ã€‚å…·ä½“è€Œè¨€ï¼Œ[è¯¦ç»†è¯´æ˜]ã€‚

æ³¨æ„ï¼š
- åŒºåˆ†ç¡®å®šäº‹å®ä¸æ¨æµ‹
- æ•°æ®å¿…é¡»å‡†ç¡®æ— è¯¯
- æ—¥æœŸã€äººåã€åœ°ç‚¹ç­‰éœ€ç²¾ç¡®""",

            QueryType.EXPLORATORY: """ä½ æ˜¯å¯Œæœ‰æ´å¯ŸåŠ›çš„è®¾è®¡ç ”ç©¶è€…ã€‚

æ¢ç´¢æ€§é—®é¢˜å¼•å¯¼æ¡†æ¶ï¼š

ã€é—®é¢˜ç†è§£ã€‘
- è¯†åˆ«æ¢ç´¢æ–¹å‘
- æ˜ç¡®çŸ¥è¯†è¾¹ç•Œ

ã€ç°æœ‰è®¤çŸ¥ã€‘
åŸºäºæ–‡æ¡£æ¢³ç†å·²çŸ¥ä¿¡æ¯

ã€æ¢ç´¢è·¯å¾„ã€‘
â–º å¯èƒ½çš„ç ”ç©¶æ–¹å‘
â–º ç›¸å…³ç†è®ºè§†è§’
â–º æ½œåœ¨å…³è”é¢†åŸŸ

ã€å¼€æ”¾æ€§æ€è€ƒã€‘
- æå‡ºå‡è®¾æ€§è§‚ç‚¹
- æŒ‡å‡ºç ”ç©¶ç©ºç™½
- å»ºè®®æ·±å…¥æ–¹å‘

ã€å­¦æœ¯è¯šä¿¡ã€‘
æ˜ç¡®æ ‡æ³¨ï¼š
- å“ªäº›æ˜¯æ–‡æ¡£æ”¯æŒçš„
- å“ªäº›æ˜¯æ¨ç†å»¶ä¼¸çš„
- å“ªäº›éœ€è¦è¿›ä¸€æ­¥éªŒè¯"""
        }

    def get_template(self, query_type: QueryType) -> str:
        """è·å–å¯¹åº”ç±»å‹çš„æ¨¡æ¿"""
        return self.templates.get(query_type, self.templates[QueryType.GENERAL])


class AnswerGenerator:
    """å¢å¼ºçš„ç­”æ¡ˆç”Ÿæˆå™¨"""

    def __init__(self,
                 api_key: str = None,
                 model_name: str = "gemini-2.0-flash",
                 enable_cot: bool = True):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨

        Args:
            api_key: APIå¯†é’¥
            model_name: æ¨¡å‹åç§°
            enable_cot: æ˜¯å¦å¯ç”¨æ€ç»´é“¾
        """
        self.api_key = api_key or os.getenv('GOOGLE_API_KEY') or os.getenv('GEMINI_API_KEY')
        self.model_name = model_name
        self.enable_cot = enable_cot
        self.llm = None

        # åˆå§‹åŒ–ç»„ä»¶
        self.template_manager = PromptTemplateManager()
        self.query_analyzer = QueryAnalyzer()

        if self.api_key:
            self._init_llm()
        else:
            logger.warning("æœªé…ç½®APIå¯†é’¥ï¼Œç”ŸæˆåŠŸèƒ½ä¸å¯ç”¨")

    def _init_llm(self):
        """åˆå§‹åŒ–LLM"""
        try:
            genai.configure(api_key=self.api_key)
            self.llm = genai.GenerativeModel(self.model_name)
            logger.info(f"LLMåˆå§‹åŒ–æˆåŠŸ: {self.model_name}")
        except Exception as e:
            logger.error(f"LLMåˆå§‹åŒ–å¤±è´¥: {e}")
            self.llm = None

    def generate(
            self,
            query: str,
            context: List[Dict[str, Any]],
            system_prompt: Optional[str] = None,
            query_type: Optional[QueryType] = None,
            config: Optional[GenerationConfig] = None
    ) -> str:
        """
        ç”Ÿæˆç­”æ¡ˆçš„ä¸»æ–¹æ³•

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸Šä¸‹æ–‡
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            query_type: æŸ¥è¯¢ç±»å‹ï¼ˆå¯é€‰ï¼‰
            config: ç”Ÿæˆé…ç½®ï¼ˆå¯é€‰ï¼‰

        Returns:
            ç”Ÿæˆçš„ç­”æ¡ˆ
        """
        if not self.llm:
            return "ç”ŸæˆåŠŸèƒ½ä¸å¯ç”¨ï¼ˆè¯·è®¾ç½®GOOGLE_API_KEYæˆ–GEMINI_API_KEYç¯å¢ƒå˜é‡ï¼‰"

        # 1. åˆ†ææŸ¥è¯¢ç±»å‹
        if query_type is None:
            query_type = self.query_analyzer.analyze(query)
            logger.info(f"è¯†åˆ«çš„æŸ¥è¯¢ç±»å‹: {query_type.value}")

        # 2. é€‰æ‹©æˆ–ä½¿ç”¨æä¾›çš„ç³»ç»Ÿæç¤ºè¯
        if system_prompt is None:
            system_prompt = self.template_manager.get_template(query_type)

        # 3. æ™ºèƒ½å¤„ç†ä¸Šä¸‹æ–‡
        processed_context = self._process_context(context, query, query_type)

        # 4. æ„å»ºå®Œæ•´æç¤ºè¯
        full_prompt = self._build_prompt(
            system_prompt=system_prompt,
            context=processed_context,
            query=query,
            query_type=query_type
        )

        # 5. è·å–ç”Ÿæˆé…ç½®
        if config is None:
            config = self._get_optimal_config(query_type)

        # 6. ç”Ÿæˆç­”æ¡ˆ
        try:
            response = self.llm.generate_content(
                full_prompt,
                generation_config=genai.GenerationConfig(
                    temperature=config.temperature,
                    top_p=config.top_p,
                    top_k=config.top_k,
                    max_output_tokens=config.max_output_tokens,
                    stop_sequences=config.stop_sequences
                )
            )

            # 7. åå¤„ç†
            answer = self._post_process(response.text, context, query_type)
            return answer

        except Exception as e:
            logger.error(f"ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {e}")
            return self._generate_fallback(query, context, query_type)

    # åœ¨ generator.py ä¸­ä¿®æ”¹ generate_with_citations æ–¹æ³•

    def generate_with_citations(self, query: str, context: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆå¸¦å¼•ç”¨çš„ç­”æ¡ˆ"""
        citation_prompt = """ä½ æ˜¯ä¸€ä¸ªè‰ºæœ¯è®¾è®¡é¢†åŸŸçš„ä¸“å®¶åŠ©æ‰‹ã€‚è¯·åŸºäºæä¾›çš„æ–‡æ¡£ä¿¡æ¯ï¼Œç»™å‡ºå‡†ç¡®ä¸”å¸¦æœ‰è§„èŒƒå¼•ç”¨çš„å›ç­”ã€‚

    å¼•ç”¨è§„èŒƒè¦æ±‚ï¼š

    1. **å®Œæ•´å¼•ç”¨æ ¼å¼**ï¼ˆé¦–æ¬¡å¼•ç”¨æŸæ–‡çŒ®æ—¶ï¼‰ï¼š
       æ ¼å¼ï¼š[ä½œè€…, å¹´ä»½, ã€Šæ–‡ç« æ ‡é¢˜ã€‹]
       ç¤ºä¾‹ï¼š[ç‹æ˜, 2020, ã€ŠåŒ…è±ªæ–¯è®¾è®¡ç†å¿µç ”ç©¶ã€‹]è®¤ä¸º...

    2. **ç®€åŒ–å¼•ç”¨æ ¼å¼**ï¼ˆåŒä¸€æ–‡çŒ®å†æ¬¡å¼•ç”¨æ—¶ï¼‰ï¼š
       æ ¼å¼ï¼š[ä½œè€…, å¹´ä»½]
       ç¤ºä¾‹ï¼šæ­£å¦‚å‰æ–‡æåˆ°çš„[ç‹æ˜, 2020]æ‰€è¿°...

    3. **ç›´æ¥å¼•ç”¨åŸæ–‡**ï¼š
       æ ¼å¼ï¼šæ ¹æ®[ä½œè€…, å¹´ä»½, ã€Šæ–‡ç« æ ‡é¢˜ã€‹]ï¼š"å¼•ç”¨çš„åŸæ–‡å†…å®¹"
       ç¤ºä¾‹ï¼šæ ¹æ®[å¼ ä¸‰, 2019, ã€Šç°ä»£è®¾è®¡å²ã€‹]ï¼š"åŒ…è±ªæ–¯æ˜¯ç°ä»£è®¾è®¡æ•™è‚²çš„å…ˆé©±"

    4. **å¤šæ–‡çŒ®ç»¼åˆå¼•ç”¨**ï¼š
       - è§‚ç‚¹ä¸€è‡´æ—¶ï¼šå¤šä½å­¦è€…[ä½œè€…1, å¹´ä»½1, ã€Šæ ‡é¢˜1ã€‹; ä½œè€…2, å¹´ä»½2, ã€Šæ ‡é¢˜2ã€‹]å…±åŒæŒ‡å‡º...
       - è§‚ç‚¹å¯¹æ¯”æ—¶ï¼šå…³äºXé—®é¢˜ï¼Œ[ä½œè€…1, å¹´ä»½1, ã€Šæ ‡é¢˜1ã€‹]è®¤ä¸º...ï¼Œè€Œ[ä½œè€…2, å¹´ä»½2, ã€Šæ ‡é¢˜2ã€‹]åˆ™æå‡º...

    5. **ç‰¹æ®Šæƒ…å†µå¤„ç†**ï¼š
       - æ— ä½œè€…ä¿¡æ¯ï¼š[ä½šå, å¹´ä»½, ã€Šæ–‡ç« æ ‡é¢˜ã€‹]
       - æ— å¹´ä»½ä¿¡æ¯ï¼š[ä½œè€…, å‡ºç‰ˆå¹´ä¸è¯¦, ã€Šæ–‡ç« æ ‡é¢˜ã€‹]
       - éƒ½æ²¡æœ‰æ—¶ï¼šæœ‰æ–‡çŒ®ã€Šæ–‡ç« æ ‡é¢˜ã€‹æŒ‡å‡º...

    å›ç­”è¦æ±‚ï¼š
    - æ¯ä¸ªå…³é”®è§‚ç‚¹éƒ½éœ€è¦æ ‡æ³¨å®Œæ•´æ¥æºï¼ˆè‡³å°‘åœ¨é¦–æ¬¡å¼•ç”¨æ—¶åŒ…å«æ–‡ç« æ ‡é¢˜ï¼‰
    - ä¿æŒå¼•ç”¨æ ¼å¼çš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§
    - åŒºåˆ†åŸæ–‡å¼•ç”¨å’Œæ¦‚æ‹¬æ€»ç»“
    - å¦‚æœæ–‡æ¡£ä¿¡æ¯ä¸è¶³ï¼Œæ˜ç¡®æŒ‡å‡ºå±€é™æ€§"""

        return self.generate(query, context, system_prompt=citation_prompt)

    def _process_context(self,
                         context: List[Dict[str, Any]],
                         query: str,
                         query_type: QueryType) -> str:
        """æ™ºèƒ½å¤„ç†ä¸Šä¸‹æ–‡"""

        # æ ¹æ®æŸ¥è¯¢ç±»å‹ç¡®å®šä¸Šä¸‹æ–‡ç­–ç•¥
        if query_type == QueryType.COMPARISON:
            return self._process_comparison_context(context, query)
        elif query_type == QueryType.TEMPORAL:
            return self._process_temporal_context(context)
        else:
            return self._process_general_context(context, query)

    def _process_general_context(self, context: List[Dict], query: str) -> str:
        """å¤„ç†ä¸€èˆ¬ä¸Šä¸‹æ–‡"""
        # æŒ‰ç›¸å…³æ€§æ’åº
        sorted_context = sorted(
            context,
            key=lambda x: x.get('score', x.get('rerank_score', 0)),
            reverse=True
        )

        formatted_docs = []
        total_chars = 0
        max_chars = 10000  # å¢åŠ ä¸Šä¸‹æ–‡å®¹é‡

        # æå–æŸ¥è¯¢å…³é”®è¯ç”¨äºé«˜äº®
        query_terms = set(self._extract_keywords(query))

        for i, doc in enumerate(sorted_context, 1):
            metadata = doc.get('metadata', {})

            # æ„å»ºæ–‡æ¡£å¤´éƒ¨ä¿¡æ¯
            doc_header = self._format_doc_header(i, metadata, doc)

            # æ™ºèƒ½æå–ç›¸å…³å†…å®¹
            text = doc.get('text', '')
            relevant_text = self._extract_relevant_content(
                text, query_terms,
                max_length=2000 if i <= 3 else 1000
            )

            # ç»„è£…æ–‡æ¡£
            doc_text = f"{doc_header}\n{relevant_text}\n{'=' * 60}\n"

            # æ£€æŸ¥é•¿åº¦é™åˆ¶
            if total_chars + len(doc_text) > max_chars:
                if i <= 3:  # ç¡®ä¿è‡³å°‘åŒ…å«å‰3ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£
                    remaining = max_chars - total_chars
                    doc_text = doc_text[:remaining] + "\n[å†…å®¹æˆªæ–­...]\n"
                    formatted_docs.append(doc_text)
                break

            formatted_docs.append(doc_text)
            total_chars += len(doc_text)

        return "\n".join(formatted_docs)

    def _process_comparison_context(self, context: List[Dict], query: str) -> str:
        """å¤„ç†æ¯”è¾ƒç±»æŸ¥è¯¢çš„ä¸Šä¸‹æ–‡"""
        # è¯†åˆ«æ¯”è¾ƒå¯¹è±¡
        comparison_terms = self._extract_comparison_terms(query)

        # æŒ‰æ¯”è¾ƒå¯¹è±¡åˆ†ç»„æ–‡æ¡£
        grouped_docs = {term: [] for term in comparison_terms}
        other_docs = []

        for doc in context:
            text = doc.get('text', '').lower()
            assigned = False

            for term in comparison_terms:
                if term.lower() in text:
                    grouped_docs[term].append(doc)
                    assigned = True
                    break

            if not assigned:
                other_docs.append(doc)

        # æ ¼å¼åŒ–åˆ†ç»„åçš„æ–‡æ¡£
        formatted_parts = []

        for term, docs in grouped_docs.items():
            if docs:
                formatted_parts.append(f"\nã€å…³äº {term} çš„æ–‡çŒ®ã€‘\n")
                for i, doc in enumerate(docs[:3], 1):
                    formatted_parts.append(self._format_single_doc(doc, i))

        if other_docs:
            formatted_parts.append("\nã€ç»¼åˆæ€§æ–‡çŒ®ã€‘\n")
            for i, doc in enumerate(other_docs[:2], 1):
                formatted_parts.append(self._format_single_doc(doc, i))

        return "".join(formatted_parts)

    def _process_temporal_context(self, context: List[Dict]) -> str:
        """å¤„ç†æ—¶é—´ç±»æŸ¥è¯¢çš„ä¸Šä¸‹æ–‡"""
        # æŒ‰æ—¶é—´æ’åº
        sorted_context = sorted(
            context,
            key=lambda x: x.get('metadata', {}).get('å¹´ä»½', 9999)
        )

        formatted_docs = []
        current_decade = None

        for doc in sorted_context:
            year = doc.get('metadata', {}).get('å¹´ä»½')

            # æŒ‰å¹´ä»£åˆ†ç»„
            if year:
                decade = (year // 10) * 10
                if decade != current_decade:
                    formatted_docs.append(f"\nã€{decade}å¹´ä»£ã€‘\n")
                    current_decade = decade

            formatted_docs.append(self._format_single_doc(doc, len(formatted_docs) + 1))

        return "".join(formatted_docs)

    def _format_doc_header(self, index: int, metadata: Dict, doc: Dict) -> str:
        """æ ¼å¼åŒ–æ–‡æ¡£å¤´éƒ¨ - å®‰å…¨ç‰ˆæœ¬"""
        # å®‰å…¨æå–å¹¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        year = str(metadata.get('å¹´ä»½', 'æœªçŸ¥'))
        author = str(metadata.get('ä½œè€…åç§°', 'æœªçŸ¥ä½œè€…'))
        title = str(metadata.get('æ–‡ç« åç§°+å‰¯æ ‡é¢˜', 'æ— æ ‡é¢˜'))
        category = str(metadata.get('åˆ†ç±»', ''))
        score = doc.get('rerank_score', doc.get('score', 'N/A'))

        # è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
        for char in ['{', '}', '[', ']']:
            title = title.replace(char, '\\' + char)
            author = author.replace(char, '\\' + char)

        # ä½¿ç”¨å­—ç¬¦ä¸²æ‹¼æ¥è€Œä¸æ˜¯f-string
        header = "ã€æ–‡æ¡£ " + str(index) + "ã€‘\n"
        header += "ğŸ“„ æ ‡é¢˜ï¼šã€Š" + title + "ã€‹\n"
        header += "ğŸ‘¤ ä½œè€…ï¼š" + author + "\n"
        header += "ğŸ“… å¹´ä»½ï¼š" + year + "\n"
        header += "ğŸ·ï¸ åˆ†ç±»ï¼š" + category + "\n"

        if isinstance(score, (int, float)):
            header += "ğŸ“Š ç›¸å…³åº¦ï¼š" + f"{score:.3f}" + "\n"
        else:
            header += "ğŸ“Š ç›¸å…³åº¦ï¼š" + str(score) + "\n"

        header += "----------------------------------------"

        return header

    def _format_single_doc(self, doc: Dict, index: int) -> str:
        """æ ¼å¼åŒ–å•ä¸ªæ–‡æ¡£"""
        metadata = doc.get('metadata', {})
        header = self._format_doc_header(index, metadata, doc)
        text = doc.get('text', '')[:1500]

        return f"{header}\n{text}...\n{'=' * 60}\n"

    def _extract_relevant_content(self, text: str, keywords: set, max_length: int) -> str:
        """æå–ç›¸å…³å†…å®¹"""
        if not text:
            return ""

        # åˆ†æ®µ
        paragraphs = text.split('\n\n')

        # è®¡ç®—æ¯æ®µçš„ç›¸å…³æ€§åˆ†æ•°
        scored_paragraphs = []
        for para in paragraphs:
            if len(para.strip()) < 20:
                continue

            para_lower = para.lower()
            # è®¡ç®—å…³é”®è¯è¦†ç›–ç‡
            keyword_score = sum(1 for kw in keywords if kw.lower() in para_lower)
            # è€ƒè™‘æ®µè½ä½ç½®ï¼ˆå¼€å¤´çš„æ®µè½é€šå¸¸æ›´é‡è¦ï¼‰
            position_score = 1.0 / (paragraphs.index(para) + 1)
            # ç»¼åˆåˆ†æ•°
            total_score = keyword_score + position_score * 0.3

            scored_paragraphs.append((total_score, para))

        # æŒ‰åˆ†æ•°æ’åº
        scored_paragraphs.sort(key=lambda x: x[0], reverse=True)

        # ç»„åˆé«˜åˆ†æ®µè½
        result_parts = []
        current_length = 0

        # å§‹ç»ˆåŒ…å«å¼€å¤´
        if paragraphs and len(paragraphs[0]) > 20:
            result_parts.append(paragraphs[0])
            current_length += len(paragraphs[0])

        # æ·»åŠ é«˜åˆ†æ®µè½
        for score, para in scored_paragraphs:
            if para not in result_parts and current_length + len(para) <= max_length:
                result_parts.append(para)
                current_length += len(para)

        # å¦‚æœå†…å®¹å¤ªå°‘ï¼Œç›´æ¥è¿”å›åŸæ–‡æˆªæ–­
        if current_length < 200:
            return text[:max_length] + "..."

        return "\n\n".join(result_parts)

    def _extract_keywords(self, query: str) -> List[str]:
        """æå–æŸ¥è¯¢å…³é”®è¯"""
        # ç®€å•å®ç°ï¼šåˆ†è¯å¹¶è¿‡æ»¤
        stopwords = {'çš„', 'æ˜¯', 'åœ¨', 'å’Œ', 'äº†', 'æœ‰', 'ä¸', 'ä¸º', 'ç­‰', 'åŠ', 'æˆ–', 'ä½†', 'è€Œ'}
        words = query.split()
        keywords = [w for w in words if len(w) > 1 and w not in stopwords]
        return keywords

    def _extract_comparison_terms(self, query: str) -> List[str]:
        """æå–æ¯”è¾ƒå¯¹è±¡"""
        # è¯†åˆ« "Aå’ŒB" "Aä¸B" "A vs B" ç­‰æ¨¡å¼
        patterns = [
            r'(.+?)[å’Œä¸è·ŸåŒ](.+?)(?:çš„|ä¹‹é—´|ç›¸æ¯”|å¯¹æ¯”|åŒºåˆ«|å·®å¼‚|ä¸åŒ)',
            r'(.+?)\s+vs\.?\s+(.+)',
            r'æ¯”è¾ƒ(.+?)å’Œ(.+)',
        ]

        for pattern in patterns:
            match = re.search(pattern, query)
            if match:
                return [match.group(1).strip(), match.group(2).strip()]

        return []

    def _build_prompt(self,
                      system_prompt: str,
                      context: str,
                      query: str,
                      query_type: QueryType) -> str:
        """æ„å»ºå®Œæ•´çš„æç¤ºè¯"""

        # æ·»åŠ æ€ç»´é“¾å¼•å¯¼
        cot_prompt = ""
        if self.enable_cot:
            cot_prompt = self._get_cot_prompt(query_type)

        # æ„å»ºå®Œæ•´æç¤º
        full_prompt = f"""{system_prompt}

{cot_prompt}

---
ğŸ“š å‚è€ƒæ–‡çŒ®èµ„æ–™ï¼š
{context}
---

â“ ç”¨æˆ·é—®é¢˜ï¼š{query}

ğŸ’¡ è¯·åŸºäºä»¥ä¸Šæ–‡çŒ®èµ„æ–™ï¼ŒæŒ‰ç…§æŒ‡å®šçš„æ¡†æ¶å’Œè¦æ±‚ï¼Œç»™å‡ºä¸“ä¸šã€å‡†ç¡®ã€æœ‰æ·±åº¦çš„å›ç­”ï¼š
"""

        return full_prompt

    def _get_cot_prompt(self, query_type: QueryType) -> str:
        """è·å–æ€ç»´é“¾æç¤º"""
        cot_prompts = {
            QueryType.ANALYTICAL: """
åˆ†ææ­¥éª¤ï¼š
1. å…ˆè¯†åˆ«é—®é¢˜çš„æ ¸å¿ƒæ¦‚å¿µå’Œåˆ†æç»´åº¦
2. è¯„ä¼°æ¯ç¯‡æ–‡çŒ®ä¸é—®é¢˜çš„ç›¸å…³æ€§
3. æå–å…³é”®è§‚ç‚¹å’Œè¯æ®
4. æ„å»ºé€»è¾‘è®ºè¯ç»“æ„
5. å½¢æˆç»¼åˆæ€§ç»“è®º
""",
            QueryType.COMPARISON: """
æ¯”è¾ƒæ­¥éª¤ï¼š
1. æ˜ç¡®æ¯”è¾ƒå¯¹è±¡å’Œæ¯”è¾ƒç»´åº¦
2. ä»æ–‡çŒ®ä¸­åˆ†åˆ«æå–ä¸¤ä¸ªå¯¹è±¡çš„ä¿¡æ¯
3. è¯†åˆ«å…±åŒç‚¹å’Œå·®å¼‚ç‚¹
4. åˆ†æå·®å¼‚çš„æ·±å±‚åŸå› 
5. æ€»ç»“æ¯”è¾ƒç»“è®º
""",
            QueryType.TEMPORAL: """
æ—¶é—´åˆ†ææ­¥éª¤ï¼š
1. å»ºç«‹æ—¶é—´åæ ‡è½´
2. æ ‡æ³¨å…³é”®æ—¶é—´èŠ‚ç‚¹
3. è¯†åˆ«å‘å±•é˜¶æ®µå’Œè½¬æŠ˜ç‚¹
4. åˆ†æå˜åŒ–çš„åŸå› å’Œå½±å“
5. æ€»ç»“æ¼”å˜è§„å¾‹
"""
        }

        return cot_prompts.get(query_type, """
æ€è€ƒæ­¥éª¤ï¼š
1. ç†è§£é—®é¢˜çš„æ ¸å¿ƒè¯‰æ±‚
2. è¯„ä¼°æ–‡çŒ®çš„ç›¸å…³æ€§å’Œå¯é æ€§
3. æå–å…³é”®ä¿¡æ¯å’Œè§‚ç‚¹
4. ç»„ç»‡è®ºè¿°ç»“æ„
5. å¾—å‡ºç»“è®ºå¹¶æ£€éªŒ
""")

    def _get_optimal_config(self, query_type: QueryType) -> GenerationConfig:
        """æ ¹æ®æŸ¥è¯¢ç±»å‹è·å–æœ€ä¼˜ç”Ÿæˆé…ç½®"""
        configs = {
            QueryType.FACTUAL: GenerationConfig(
                temperature=0.3,  # é™ä½éšæœºæ€§
                top_p=0.8,
                top_k=20
            ),
            QueryType.ANALYTICAL: GenerationConfig(
                temperature=0.7,  # å¹³è¡¡åˆ›é€ æ€§å’Œå‡†ç¡®æ€§
                top_p=0.9,
                top_k=40,
                max_output_tokens=3000  # å…è®¸æ›´é•¿çš„åˆ†æ
            ),
            QueryType.EXPLORATORY: GenerationConfig(
                temperature=0.8,  # æé«˜åˆ›é€ æ€§
                top_p=0.95,
                top_k=50
            )
        }

        return configs.get(query_type, GenerationConfig())

    def _post_process(self, answer: str, context: List[Dict], query_type: QueryType) -> str:
        """åå¤„ç†ç”Ÿæˆçš„ç­”æ¡ˆ"""
        if not answer.strip():
            return "æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆæœ‰æ•ˆç­”æ¡ˆã€‚"

        # æ·»åŠ å¼•ç”¨å®Œæ•´æ€§æ£€æŸ¥
        answer = self._verify_citations(answer, context)

        # æ·»åŠ ä¿¡æ¯æ¥æºè¯´æ˜
        source_note = self._generate_source_note(context, query_type)

        return f"{answer}\n\n{source_note}"

    def _verify_citations(self, answer: str, context: List[Dict]) -> str:
        """éªŒè¯å¼•ç”¨çš„å‡†ç¡®æ€§"""
        # æå–ç­”æ¡ˆä¸­çš„å¼•ç”¨
        citation_pattern = r'\[([^,\]]+),\s*(\d{4})\]'
        citations = re.findall(citation_pattern, answer)

        # éªŒè¯æ¯ä¸ªå¼•ç”¨æ˜¯å¦åœ¨ä¸Šä¸‹æ–‡ä¸­å­˜åœ¨
        valid_authors = set()
        valid_years = set()

        for doc in context:
            metadata = doc.get('metadata', {})
            author = metadata.get('ä½œè€…åç§°', '')
            year = metadata.get('å¹´ä»½', '')

            if author:
                valid_authors.add(author)
            if year:
                valid_years.add(str(year))

        # æ ‡è®°å¯ç–‘å¼•ç”¨
        for author, year in citations:
            if author not in valid_authors or year not in valid_years:
                answer = answer.replace(f'[{author}, {year}]', f'[{author}, {year}]*')

        return answer

    def _generate_source_note(self, context: List[Dict], query_type: QueryType) -> str:
        """ç”Ÿæˆæ¥æºè¯´æ˜"""
        doc_count = len(context)
        years = []
        categories = set()

        for doc in context:
            metadata = doc.get('metadata', {})
            year = metadata.get('å¹´ä»½')
            category = metadata.get('åˆ†ç±»')

            if year:
                years.append(year)
            if category:
                categories.add(category)

        year_range = f"{min(years)}-{max(years)}" if years else "æ—¶é—´è·¨åº¦ä¸æ˜"
        category_list = "ã€".join(list(categories)[:3]) if categories else "å¤šä¸ªé¢†åŸŸ"

        source_note = f"""---
ğŸ“– **ä¿¡æ¯æ¥æºè¯´æ˜**
- å‚è€ƒæ–‡çŒ®æ•°ï¼š{doc_count} ç¯‡
- æ—¶é—´è·¨åº¦ï¼š{year_range}
- æ¶‰åŠé¢†åŸŸï¼š{category_list}
- ç”Ÿæˆæ—¶é—´ï¼š{self._get_current_time()}

*æ³¨ï¼šæ ‡æœ‰*çš„å¼•ç”¨å¯èƒ½éœ€è¦è¿›ä¸€æ­¥æ ¸å®*"""

        return source_note

    def _generate_fallback(self, query: str, context: List[Dict], query_type: QueryType) -> str:
        """ç”Ÿæˆé™çº§ç­”æ¡ˆ"""
        if not context:
            return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ä¸æ‚¨çš„é—®é¢˜ç›¸å…³çš„æ–‡æ¡£ã€‚è¯·å°è¯•ï¼š\n1. ä½¿ç”¨æ›´é€šç”¨çš„å…³é”®è¯\n2. æ£€æŸ¥æ‹¼å†™æ˜¯å¦æ­£ç¡®\n3. ç®€åŒ–æŸ¥è¯¢å†…å®¹"

        # æ ¹æ®æŸ¥è¯¢ç±»å‹ç”Ÿæˆç»“æ„åŒ–çš„é™çº§ç­”æ¡ˆ
        answer = f"å…³äºæ‚¨çš„é—®é¢˜ã€Œ{query}ã€ï¼Œè™½ç„¶æ— æ³•ç”Ÿæˆå®Œæ•´ç­”æ¡ˆï¼Œä½†æ‰¾åˆ°ä»¥ä¸‹ç›¸å…³èµ„æ–™ä¾›å‚è€ƒï¼š\n\n"

        # åˆ—å‡ºç›¸å…³æ–‡æ¡£
        for i, doc in enumerate(context[:5], 1):
            metadata = doc.get('metadata', {})
            title = metadata.get('æ–‡ç« åç§°+å‰¯æ ‡é¢˜', 'æ— æ ‡é¢˜')
            author = metadata.get('ä½œè€…åç§°', 'æœªçŸ¥ä½œè€…')
            year = metadata.get('å¹´ä»½', 'æœªçŸ¥å¹´ä»½')

            answer += f"**[{i}] {title}**\n"
            answer += f"   ä½œè€…ï¼š{author} | å¹´ä»½ï¼š{year}\n"

            # æ·»åŠ ç®€çŸ­æ‘˜è¦
            text = doc.get('text', '')[:200]
            if text:
                answer += f"   æ‘˜è¦ï¼š{text}...\n\n"

        # æ·»åŠ å»ºè®®
        suggestions = self._get_fallback_suggestions(query_type)
        answer += f"\nğŸ’¡ **å»ºè®®**ï¼š\n{suggestions}"

        return answer

    def _get_fallback_suggestions(self, query_type: QueryType) -> str:
        """è·å–é™çº§å»ºè®®"""
        suggestions = {
            QueryType.COMPARISON: "â€¢ å°è¯•åˆ†åˆ«æœç´¢æ¯ä¸ªæ¯”è¾ƒå¯¹è±¡\nâ€¢ ä½¿ç”¨æ›´å…·ä½“çš„æ¯”è¾ƒç»´åº¦",
            QueryType.TEMPORAL: "â€¢ å°è¯•æœç´¢ç‰¹å®šå¹´ä»£æˆ–æ—¶æœŸ\nâ€¢ ä½¿ç”¨ å‘å±•\æ¼”å˜ ç­‰å…³é”®è¯",
            QueryType.DEFINITION: "â€¢ æŸ¥æ‰¾è¯¥æ¦‚å¿µçš„ä¸Šä½æ¦‚å¿µ\nâ€¢ æœç´¢ç›¸å…³çš„ç†è®ºæ¡†æ¶",
            QueryType.ANALYTICAL: "â€¢ å°†é—®é¢˜åˆ†è§£ä¸ºæ›´å°çš„å­é—®é¢˜\nâ€¢ å¯»æ‰¾ç›¸å…³çš„æ¡ˆä¾‹ç ”ç©¶"
        }

        return suggestions.get(query_type, "â€¢ ç®€åŒ–æŸ¥è¯¢è¯\nâ€¢ å°è¯•ç›¸å…³æ¦‚å¿µ\nâ€¢ æŸ¥çœ‹æ¨èé˜…è¯»")

    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M")

    def set_api_key(self, api_key: str):
        """è®¾ç½®APIå¯†é’¥"""
        self.api_key = api_key
        if api_key:
            self._init_llm()

    def is_available(self) -> bool:
        """æ£€æŸ¥ç”ŸæˆåŠŸèƒ½æ˜¯å¦å¯ç”¨"""
        return self.llm is not None


class QueryAnalyzer:
    """æŸ¥è¯¢åˆ†æå™¨"""

    def analyze(self, query: str) -> QueryType:
        """åˆ†ææŸ¥è¯¢ç±»å‹"""
        query_lower = query.lower()

        # å®šä¹‰å…³é”®è¯æ˜ å°„
        type_keywords = {
            QueryType.DEFINITION: ['æ˜¯ä»€ä¹ˆ', 'ä»€ä¹ˆæ˜¯', 'å®šä¹‰', 'æ¦‚å¿µ', 'å«ä¹‰', 'è§£é‡Š'],
            QueryType.COMPARISON: ['æ¯”è¾ƒ', 'å¯¹æ¯”', 'åŒºåˆ«', 'ä¸åŒ', 'ç›¸åŒ', 'å·®å¼‚', 'vs', 'å’Œ.*çš„å…³ç³»'],
            QueryType.TEMPORAL: ['ä½•æ—¶', 'ä»€ä¹ˆæ—¶å€™', 'å†å²', 'å‘å±•', 'æ¼”å˜', 'èµ·æº', 'æœ€æ—©', 'æœ€æ–°'],
            QueryType.ANALYTICAL: ['ä¸ºä»€ä¹ˆ', 'å¦‚ä½•', 'æ€æ ·', 'åˆ†æ', 'è¯„ä»·', 'å½±å“', 'æ„ä¹‰', 'ä½œç”¨'],
            QueryType.FACTUAL: ['è°', 'å“ªé‡Œ', 'å¤šå°‘', 'å‡ ä¸ª', 'ç¬¬ä¸€', 'æœ€å¤§', 'æœ€å°'],
            QueryType.EXPLORATORY: ['å¯èƒ½', 'æ˜¯å¦', 'æœ‰å“ªäº›', 'è¿˜æœ‰ä»€ä¹ˆ', 'å…¶ä»–', 'ç›¸å…³']
        }

        # æ£€æŸ¥æ¯ç§ç±»å‹çš„å…³é”®è¯
        for query_type, keywords in type_keywords.items():
            for keyword in keywords:
                if re.search(keyword, query_lower):
                    return query_type

        # é»˜è®¤è¿”å›é€šç”¨ç±»å‹
        return QueryType.GENERAL


# ä¾¿æ·å‡½æ•°
def create_generator(api_key: str = None, enable_cot: bool = True) -> AnswerGenerator:
    """åˆ›å»ºç­”æ¡ˆç”Ÿæˆå™¨çš„ä¾¿æ·å‡½æ•°"""
    return AnswerGenerator(api_key=api_key, enable_cot=enable_cot)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    generator = create_generator()

    # æ¨¡æ‹Ÿä¸Šä¸‹æ–‡
    test_context = [
        {
            'text': 'åŒ…è±ªæ–¯ï¼ˆBauhausï¼‰æ˜¯1919å¹´åœ¨å¾·å›½é­ç›æˆç«‹çš„ä¸€æ‰€è®¾è®¡å­¦æ ¡...',
            'metadata': {
                'å¹´ä»½': 2020,
                'ä½œè€…åç§°': 'å¼ ä¸‰',
                'æ–‡ç« åç§°+å‰¯æ ‡é¢˜': 'åŒ…è±ªæ–¯çš„å†å²ä¸å½±å“',
                'åˆ†ç±»': 'è®¾è®¡å²'
            },
            'score': 0.95
        }
    ]

    # æµ‹è¯•ä¸åŒç±»å‹çš„æŸ¥è¯¢
    test_queries = [
        "ä»€ä¹ˆæ˜¯åŒ…è±ªæ–¯ï¼Ÿ",
        "æ¯”è¾ƒåŒ…è±ªæ–¯å’Œè£…é¥°è‰ºæœ¯è¿åŠ¨",
        "åŒ…è±ªæ–¯æ˜¯ä»€ä¹ˆæ—¶å€™æˆç«‹çš„ï¼Ÿ",
        "åˆ†æåŒ…è±ªæ–¯å¯¹ç°ä»£è®¾è®¡çš„å½±å“"
    ]

    for query in test_queries:
        print(f"\næŸ¥è¯¢: {query}")
        print("å›ç­”: ", generator.generate(query, test_context))
        print("-" * 80)